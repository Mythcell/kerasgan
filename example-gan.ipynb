{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example GAN\n",
    "***\n",
    "A quick and simple GAN trained with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "from kerasgan import GAN, GANSnapshot, GANCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 128\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# combine all images and rescale to [-1,1]\n",
    "image_data = np.concatenate((X_train,X_test))\n",
    "image_data = image_data[...,np.newaxis].astype('float32')/127.5 - 1\n",
    "\n",
    "# sanity checks\n",
    "print(image_data.shape, image_data.dtype, np.max(image_data), np.min(image_data))\n",
    "\n",
    "# create tf dataset \n",
    "image_data = tf.data.Dataset.from_tensor_slices(image_data).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Generator\n",
    "The generator should take a latent vector as its input and output an image. This example will use tranpose convolutions with a stride length of 2. Note the use of output_padding=1 in the first `Conv2DTranpose`. This ensures the dimensions go from (4,4,128) to (7,7,64) instead of (8,8,64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "gen_input = layers.Input(shape=(LATENT_DIM,))\n",
    "x = layers.Dense(4*4*128, use_bias=False)(gen_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((4,4,128))(x)\n",
    "x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', output_padding=1, use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "gen_output = layers.Conv2DTranspose(1, kernel_size=4, strides=2, padding='same', activation='tanh')(x)\n",
    "generator = keras.Model(inputs=gen_input, outputs=gen_output, name='generator')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Discriminator\n",
    "The discriminator should take an image and output a single value. This example uses regular, strided convolutions. Note there is no batch normalisation in the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_input = layers.Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(32, kernel_size=3, strides=2, padding='same')(dsc_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "dsc_output = layers.Dense(1)(x) # note there is no activation!\n",
    "discriminator = keras.Model(inputs=dsc_input, outputs=dsc_output, name='discriminator')\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the GAN\n",
    "Simply instantiate a `GAN` object with the two models, compile and fit. Don't forget to pass `LATENT_DIM` to the `GAN` constructor.\n",
    "\n",
    "The example below also includes two callbacks:\n",
    "- `GANSnapshot` will produce a matplotlib figure showing some example images produced by the generator at each step. You can provide a  seed if you wish, otherwise one will be randomly generated. By default, this callback will plot 32 examples. The figures are merely displayed in the Notebook, but you can save these as png files by setting `save_snapshots=True`.\n",
    "\n",
    "- `GANCheckpoint` will, in its default settings, save both the generator and discriminator as .h5 files in the directory 'gan_checkpoints' every 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    latent_dim=LATENT_DIM\n",
    ")\n",
    "\n",
    "gan.compile(\n",
    "    generator_optimizer=keras.optimizers.Adam(learning_rate=2e-4,beta_1=0.05),\n",
    "    discriminator_optimizer=keras.optimizers.Adam(learning_rate=2e-4,beta_1=0.05)\n",
    ")\n",
    "\n",
    "hist = gan.fit(\n",
    "    image_data, epochs=50, verbose=2,\n",
    "    callbacks = [GANSnapshot(), GANCheckpoint()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Callbacks Examples\n",
    "Both callbacks have several options for greater flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display snapshots using the provided seed (64 examples)\n",
    "seed = tf.random.normal(shape=(64,LATENT_DIM))\n",
    "GANSnapshot(seed=seed)\n",
    "\n",
    "# display 100 examples \n",
    "GANSnapshot(num_images=100)\n",
    "\n",
    "# save snapshots every 10 epochs, and write the files to the directory 'mysnapshots'.\n",
    "# files will be named mymodel_0000.png, mymodel_0010.png, mymodel_0020.png, etc\n",
    "GANSnapshot(save_snapshots=True, save_dir='mysnapshots',\n",
    "    save_freq=10, save_prefix='mymodel')\n",
    "\n",
    "# save snapshots of 42 examples with the 'cividis' colormap and a higher resolution\n",
    "GANSnapshot(num_images=42, save_snapshots=True, cmap='cividis', dpi=200)\n",
    "\n",
    "# save just the generator, every 100 epochs\n",
    "GANCheckpoint(save_freq=100, save_discriminator=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mypy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16baf165b6058e6d9020bd23ce75d93525d788d43e3c319043bbc1a04ebbea74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
