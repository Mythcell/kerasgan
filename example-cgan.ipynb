{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example CGAN\n",
    "***\n",
    "A quick and simple CGAN trained with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "from kerasgan import CGAN, CGANSnapshot, CGANClassSnapshot, GANCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 128\n",
    "NUM_CLASSES = 10\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# combine all images and rescale to [-1,1]\n",
    "image_data = np.concatenate((X_train,X_test))\n",
    "image_data = image_data[...,np.newaxis].astype('float32')/127.5 - 1\n",
    "# combine labels\n",
    "image_labels = np.concatenate((y_train,y_test))\n",
    "# note that labels must be an array of integers\n",
    "# in order to work with CGANSnapshot and/or CGANClassSnapshot\n",
    "\n",
    "# sanity checks\n",
    "print(image_data.shape, image_data.dtype, np.max(image_data), np.min(image_data))\n",
    "\n",
    "# create tf dataset (both data and labels)\n",
    "training_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (image_data,image_labels)).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Generator\n",
    "The generator should accept two inputs: a latent vector of size equal to `LATENT_DIM`, and a label. In this example the label is transformed into a higher-dimensional embedding of length 64, before being concatenated with the latent vector. Note this is just one of many ways of incorporating labels; you could, for instance, use a Multiply() layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "# generator\n",
    "latent_input = layers.Input(shape=(LATENT_DIM,))\n",
    "label_input = layers.Input(shape=(1,))\n",
    "embedding = layers.Embedding(input_dim=NUM_CLASSES, output_dim=32, input_length=1)(label_input)\n",
    "embedding = layers.Flatten()(embedding)\n",
    "x = layers.Concatenate()([latent_input, embedding]) # shape = (LATENT_DIM+64,)\n",
    "x = layers.Dense(4*4*128, use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((4,4,128))(x)\n",
    "x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', output_padding=1, use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "gen_output = layers.Conv2DTranspose(1, kernel_size=4, strides=2, padding='same', activation='tanh')(x)\n",
    "generator = keras.Model(inputs=[latent_input, label_input], outputs=gen_output, name='generator')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Discriminator\n",
    "The discriminator also accepts two inputs; an image and a label. In this example the label is transformed into a higher dimensional embedding, which is eventually reshaped and concatenated to the image as an additional \"channel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = layers.Input(shape=(28,28,1))\n",
    "label_input = layers.Input(shape=(1,))\n",
    "embedding = layers.Embedding(input_dim=10, output_dim=28*28, input_length=1)(label_input)\n",
    "embedding = layers.Flatten()(embedding)\n",
    "embedding = layers.Reshape((28,28,1))(embedding)\n",
    "x = layers.Concatenate()([image_input, embedding]) # shape = (28,28,2)\n",
    "x = layers.Conv2D(32, kernel_size=3, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "dsc_output = layers.Dense(1)(x)\n",
    "discriminator = keras.Model(inputs=[image_input, label_input], outputs=dsc_output, name='discriminator')\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CGAN\n",
    "As with the normal GAN, training is a simple 3-step process. Don't forget to pass both the latent vector dimension `LATENT_DIM` as well as the number of classes `NUM_CLASSES` to the `CGAN` constructor; the latter is important as it is used as an upper bound for generating labels.\n",
    "\n",
    "#### A Note on Labels\n",
    "The callbacks `CGANSnapshot` and `CGANClassSnapshot` are both capable of randomly generating labels to pass to the generator. These labels are strictly integers in the range 0, 1, ..., `NUM_CLASSES`-1. Ensure your generator model and training data all use integer labels before using these callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan = CGAN(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "cgan.compile(\n",
    "    generator_optimizer=keras.optimizers.Adam(learning_rate=2e-4,beta_1=0.05),\n",
    "    discriminator_optimizer=keras.optimizers.Adam(learning_rate=2e-4,beta_1=0.05)\n",
    ")\n",
    "\n",
    "hist = cgan.fit(\n",
    "    training_data, epochs=30, verbose=2,\n",
    "    callbacks = [CGANClassSnapshot(examples_per_class=4), GANCheckpoint(save_dir='cgan_checkpoints')]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGAN Callbacks\n",
    "Both `CGANSnapshot` and `CGANClassSnapshot` are intended to be used with `CGAN.` **Do not use `GANSnapshot` with `CGAN`, it should instead only be used with `GAN`!**\n",
    "\n",
    "`CGANSnapshot` is identical to `GANSnapshot` but instead also randomly generates labels.\n",
    "\n",
    "`CGANClassSnapshot` is the recommended snapshot callback to use. By default, it will generate 3 rows of examples with each column corresponding to a different label.\n",
    "\n",
    "Each of these callbacks has several additional options that allow for greater flexibility. Some examples are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display snapshots using the provided seed (will generate random labels)\n",
    "seed = tf.random.normal(shape=(32,LATENT_DIM))\n",
    "CGANSnapshot(seed=seed)\n",
    "\n",
    "# display snapshots using the provided labels (will generate a random seed)\n",
    "labels = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "CGANSnapshot(labels=labels)\n",
    "\n",
    "# display snapshots using the provided seed and labels\n",
    "CGANSnapshot(seed=seed, labels=labels)\n",
    "\n",
    "# save snapshots with 100 images into the directory 'mysnapshots'\n",
    "CGANSnapshot(num_images=100, save_snapshots=True, save_dir='mysnapshots')\n",
    "\n",
    "# save snapshots every 10 epochs with 5 examples per class into the directory 'myclass_snapshots'\n",
    "CGANClassSnapshot(examples_per_class=5, save_snapshots=True,\n",
    "    save_freq=10, save_dir='myclass_snapshots')\n",
    "\n",
    "# display snapshots with 5 examples per class, except make each row show a different class\n",
    "CGANClassSnapshot(examples_per_class=5, columns_indicate='examples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mypy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16baf165b6058e6d9020bd23ce75d93525d788d43e3c319043bbc1a04ebbea74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
